{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/MostleeMolde/PYTHONCOURSE101/blob/main/Modules/3.%20Data%20structures%20and%20Methods/3.3%20Strings/string_tasks.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6lFTePIUzy1z"
      },
      "source": [
        "# TASK 1\n",
        "Below is a dictionary with some movie data in it. Some of the movies have missing data and your job is to replace the missing data with `None`.\n",
        "\n",
        "***All missing data is represented as an empty string***\n",
        "\n",
        "## Example output \n",
        "```python\n",
        "# Original Dataset\n",
        "[\n",
        "    {\n",
        "        'Title': 'Star wars Episode 1',\n",
        "        'Duration': \"\",\n",
        "        'Release Year': \"\"\n",
        "    }\n",
        "]\n",
        "\n",
        "# Cleaned dataset\n",
        "[\n",
        "    {\n",
        "        'Title': 'Star wars Episode 1',\n",
        "        'Duration': None,\n",
        "        'Release Year': None\n",
        "    }\n",
        "]\n",
        "```"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "8Tleo1v_zy10",
        "outputId": "24380b8f-be27-48eb-fe7d-1344f49d793c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[{'Duration': None, 'Release Year': None, 'Title': 'Star Wars Episode 1'},\n",
              " {'Duration': '103', 'Release Year': None, 'Title': 'Jungle Book'},\n",
              " {'Duration': '150', 'Release Year': '2014', 'Title': 'Interstellar'},\n",
              " {'Duration': None, 'Release Year': None, 'Title': None},\n",
              " {'Duration': '126', 'Release Year': None, 'Title': 'Star Wars Episode 2'},\n",
              " {'Duration': None, 'Release Year': '2019', 'Title': 'Toy story 4'}]"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ],
      "source": [
        "var = [\n",
        "    {\n",
        "        'Title': 'Star Wars Episode 1',\n",
        "        'Duration': \"\",\n",
        "        'Release Year': \"\"\n",
        "    },\n",
        "    {\n",
        "        'Title': 'Jungle Book',\n",
        "        'Duration': \"103\",\n",
        "        'Release Year': \"\"\n",
        "    },{\n",
        "        'Title': 'Interstellar',\n",
        "        'Duration': \"150\",\n",
        "        'Release Year': \"2014\"\n",
        "    },{\n",
        "        'Title': '',\n",
        "        'Duration': \"\",\n",
        "        'Release Year': \"\"\n",
        "    },{\n",
        "        'Title': 'Star Wars Episode 2',\n",
        "        'Duration': \"126\",\n",
        "        'Release Year': \"\"\n",
        "    },{\n",
        "        'Title': 'Toy story 4',\n",
        "        'Duration': \"\",\n",
        "        'Release Year': \"2019\"\n",
        "    },\n",
        "]\n",
        "for i in var:\n",
        "  for x in i:\n",
        "    if i[x] == \"\":\n",
        "      i[x] = None\n",
        "var"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LT-gSPwqzy11"
      },
      "source": [
        "# TASK 2\n",
        "You're given a list of phrases and you're asked to complete the following steps for each phrase in the list.\n",
        "\n",
        "* Replace all of the commas with empty strings\n",
        "* split the phrases and update the list to be the result of the split.\n",
        "\n",
        "## Example output\n",
        "```python\n",
        "# BEFORE\n",
        "[\n",
        "    'hello, world',\n",
        "    'hello, universe', \n",
        "    'hello, Gabe'\n",
        "]\n",
        "\n",
        "# AFTER\n",
        "[\n",
        "    ['hello', 'world'],\n",
        "    ['hello', 'universe'],\n",
        "    ['hello', 'Gabe']\n",
        "]\n",
        "```\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "id": "5fNakBuDzy11",
        "outputId": "f110cbc0-500a-455b-a86d-93d635d02e82",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[['If', 'you', 'are', 'ill', 'you', 'ought', 'to', 'see', 'a', 'doctor'],\n",
              " ['When',\n",
              "  'the',\n",
              "  'snow',\n",
              "  'stops',\n",
              "  'falling',\n",
              "  \"we'll\",\n",
              "  'shovel',\n",
              "  'the',\n",
              "  'driveway'],\n",
              " ['While',\n",
              "  'I',\n",
              "  'was',\n",
              "  'eating',\n",
              "  'the',\n",
              "  'cat',\n",
              "  'scratched',\n",
              "  'at',\n",
              "  'the',\n",
              "  'door']]"
            ]
          },
          "metadata": {},
          "execution_count": 29
        }
      ],
      "source": [
        "var = ['If you are ill, you ought to see a doctor', \"When the snow stops falling, we'll shovel the driveway\", 'While I was eating, the cat scratched at the door']\n",
        "#TODO\n",
        "for i in range(len(var)):\n",
        "   var[i] = var[i].replace(\",\",\"\").split(\" \")\n",
        "var\n",
        "  \n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c4x5Qccnzy12"
      },
      "source": [
        "# TASK 3\n",
        "Use the predefined `get_word` function to generate a list of 20 words. Then out of those 20 words, find all the words that contain repeating characters. For example, `book` has repeating characters because the letter `o` is followed by another `o`.\n",
        "\n",
        "## Example output\n",
        "```python\n",
        "original = ['growing',\n",
        " 'leafinesses',\n",
        " 'grivets',\n",
        " 'bigmouthed',\n",
        " 'militarizing',\n",
        " 'safenesses',\n",
        " 'credulousness'\n",
        "]\n",
        "\n",
        "repeats = [\n",
        "    'leafinesses',\n",
        "    'safenesses',\n",
        "    'credulousness'\n",
        "]\n",
        "\n",
        "print(\"There were 3 words with repeating characters\")\n",
        "```"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {
        "id": "TlgKQuD3zy12",
        "outputId": "b49d5437-e6b4-4f97-9784-4e9e2e25383b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['corrects', 'bombproofing', 'residentially', 'nymphettes', 'cressets']"
            ]
          },
          "metadata": {},
          "execution_count": 41
        }
      ],
      "source": [
        "import requests\n",
        "def get_word():\n",
        "    word = requests.get(\"https://random-word-api.herokuapp.com/word?number=20\").json()\n",
        "    return word\n",
        "\n",
        "repeats = []\n",
        "for i in get_word():\n",
        "  char = \"\"\n",
        "  for x in i:\n",
        "    if x == char:\n",
        "      repeats.append(i)\n",
        "    char = x\n",
        "repeats = list(set(repeats))\n",
        "repeats\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "usA6VI2fzy12"
      },
      "source": [
        "# TASK 4\n",
        "Using the same `get_word` function from the previous task, generate another 20 words. Then for each word, create a dictionary containing the count of each letter in the word and how many unique characters are in the word. Then add the dictionary to a list called `counts` and print out the list of dictionaries.\n",
        "\n",
        "## Example output\n",
        "```python \n",
        "words = [\n",
        "    'banana',\n",
        "    'apple',\n",
        "    'blueberry'\n",
        "]\n",
        "\n",
        "counts = [\n",
        "    {\n",
        "        \"b\": 1,\n",
        "        \"a\": 3,\n",
        "        \"n\":2,\n",
        "        'unique characters': 3\n",
        "    },\n",
        "    {\n",
        "        \"a\": 1,\n",
        "        \"p\":2,\n",
        "        \"l\": 1,\n",
        "        \"e\": 1,\n",
        "        'unique characters': 4 \n",
        "    },\n",
        "    {\n",
        "        \"b\": 2,\n",
        "        'l': 1,\n",
        "        'u': 1,\n",
        "        'e': 2,\n",
        "        'r': 2,\n",
        "        'y': 1,\n",
        "        \"unique characters\": 6\n",
        "    }\n",
        "]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 45,
      "metadata": {
        "id": "kFH2FiS9zy13",
        "outputId": "74110402-1a98-489c-89d5-4089566305d3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[{'Word': 'papacy', 'a': 2, 'c': 1, 'p': 2, 'unique characters': 1, 'y': 1},\n",
              " {'Word': 'piperazine',\n",
              "  'a': 1,\n",
              "  'e': 2,\n",
              "  'i': 2,\n",
              "  'n': 1,\n",
              "  'p': 2,\n",
              "  'r': 1,\n",
              "  'unique characters': 1,\n",
              "  'z': 1},\n",
              " {'Word': 'midrash',\n",
              "  'a': 1,\n",
              "  'd': 1,\n",
              "  'h': 1,\n",
              "  'i': 1,\n",
              "  'm': 1,\n",
              "  'r': 1,\n",
              "  's': 1,\n",
              "  'unique characters': 1},\n",
              " {'Word': 'ureases',\n",
              "  'a': 1,\n",
              "  'e': 2,\n",
              "  'r': 1,\n",
              "  's': 2,\n",
              "  'u': 1,\n",
              "  'unique characters': 1},\n",
              " {'Word': 'willingness',\n",
              "  'e': 1,\n",
              "  'g': 1,\n",
              "  'i': 2,\n",
              "  'l': 2,\n",
              "  'n': 2,\n",
              "  's': 2,\n",
              "  'unique characters': 1,\n",
              "  'w': 1},\n",
              " {'Word': 'disco',\n",
              "  'c': 1,\n",
              "  'd': 1,\n",
              "  'i': 1,\n",
              "  'o': 1,\n",
              "  's': 1,\n",
              "  'unique characters': 1},\n",
              " {'Word': 'machrees',\n",
              "  'a': 1,\n",
              "  'c': 1,\n",
              "  'e': 2,\n",
              "  'h': 1,\n",
              "  'm': 1,\n",
              "  'r': 1,\n",
              "  's': 1,\n",
              "  'unique characters': 1},\n",
              " {'Word': 'coronate',\n",
              "  'a': 1,\n",
              "  'c': 1,\n",
              "  'e': 1,\n",
              "  'n': 1,\n",
              "  'o': 2,\n",
              "  'r': 1,\n",
              "  't': 1,\n",
              "  'unique characters': 1},\n",
              " {'Word': 'flagships',\n",
              "  'a': 1,\n",
              "  'f': 1,\n",
              "  'g': 1,\n",
              "  'h': 1,\n",
              "  'i': 1,\n",
              "  'l': 1,\n",
              "  'p': 1,\n",
              "  's': 2,\n",
              "  'unique characters': 1},\n",
              " {'Word': 'hoodiest',\n",
              "  'd': 1,\n",
              "  'e': 1,\n",
              "  'h': 1,\n",
              "  'i': 1,\n",
              "  'o': 2,\n",
              "  's': 1,\n",
              "  't': 1,\n",
              "  'unique characters': 1},\n",
              " {'Word': 'gainlier',\n",
              "  'a': 1,\n",
              "  'e': 1,\n",
              "  'g': 1,\n",
              "  'i': 2,\n",
              "  'l': 1,\n",
              "  'n': 1,\n",
              "  'r': 1,\n",
              "  'unique characters': 1},\n",
              " {'Word': 'teguments',\n",
              "  'e': 2,\n",
              "  'g': 1,\n",
              "  'm': 1,\n",
              "  'n': 1,\n",
              "  's': 1,\n",
              "  't': 2,\n",
              "  'u': 1,\n",
              "  'unique characters': 1},\n",
              " {'Word': 'tsarinas',\n",
              "  'a': 2,\n",
              "  'i': 1,\n",
              "  'n': 1,\n",
              "  'r': 1,\n",
              "  's': 2,\n",
              "  't': 1,\n",
              "  'unique characters': 1},\n",
              " {'Word': 'loftless',\n",
              "  'e': 1,\n",
              "  'f': 1,\n",
              "  'l': 2,\n",
              "  'o': 1,\n",
              "  's': 2,\n",
              "  't': 1,\n",
              "  'unique characters': 1},\n",
              " {'Word': 'amylogen',\n",
              "  'a': 1,\n",
              "  'e': 1,\n",
              "  'g': 1,\n",
              "  'l': 1,\n",
              "  'm': 1,\n",
              "  'n': 1,\n",
              "  'o': 1,\n",
              "  'unique characters': 1,\n",
              "  'y': 1},\n",
              " {'Word': 'heartlessness',\n",
              "  'a': 1,\n",
              "  'e': 3,\n",
              "  'h': 1,\n",
              "  'l': 1,\n",
              "  'n': 1,\n",
              "  'r': 1,\n",
              "  's': 4,\n",
              "  't': 1,\n",
              "  'unique characters': 1},\n",
              " {'Word': 'enrich',\n",
              "  'c': 1,\n",
              "  'e': 1,\n",
              "  'h': 1,\n",
              "  'i': 1,\n",
              "  'n': 1,\n",
              "  'r': 1,\n",
              "  'unique characters': 1},\n",
              " {'Word': 'spoonies',\n",
              "  'e': 1,\n",
              "  'i': 1,\n",
              "  'n': 1,\n",
              "  'o': 2,\n",
              "  'p': 1,\n",
              "  's': 2,\n",
              "  'unique characters': 1},\n",
              " {'Word': 'ravages',\n",
              "  'a': 2,\n",
              "  'e': 1,\n",
              "  'g': 1,\n",
              "  'r': 1,\n",
              "  's': 1,\n",
              "  'unique characters': 1,\n",
              "  'v': 1},\n",
              " {'Word': 'certifiably',\n",
              "  'a': 1,\n",
              "  'b': 1,\n",
              "  'c': 1,\n",
              "  'e': 1,\n",
              "  'f': 1,\n",
              "  'i': 2,\n",
              "  'l': 1,\n",
              "  'r': 1,\n",
              "  't': 1,\n",
              "  'unique characters': 1,\n",
              "  'y': 1}]"
            ]
          },
          "metadata": {},
          "execution_count": 45
        }
      ],
      "source": [
        "#TODO\n",
        "counts = []\n",
        "for i in get_word():\n",
        "  nums = {\"Word\": i}\n",
        "  for x in i:\n",
        "    nums.setdefault(x,0)\n",
        "    nums[x] += 1\n",
        "  nums[\"unique characters\"] = len(list(set(x)))\n",
        "  counts.append(nums)\n",
        "counts\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "huyrvoo0zy13"
      },
      "source": [
        "# TASK 5\n",
        "Below is a function that will return to you samples of transcripts from different podcasts. A common task in NLP is converting a section of text into a numerical representation for the computer to understand. Your task is to create a mapping that maps each unique word in the text to a value, then replace each word in the text with its corresponding value. \n",
        "\n",
        "## Example output\n",
        "```python\n",
        "text = \"This is some random text that needs to be encoded to numbers so that the computer can understand it\"\n",
        "\n",
        "mapping = {'text': '1',\n",
        " 'that': '2',\n",
        " 'it': '3',\n",
        " 'be': '4',\n",
        " 'encoded': '5',\n",
        " 'numbers': '6',\n",
        " 'can': '7',\n",
        " 'so': '8',\n",
        " 'is': '9',\n",
        " 'to': '10',\n",
        " 'computer': '11',\n",
        " 'understand': '12',\n",
        " 'random': '13',\n",
        " 'needs': '14',\n",
        " 'some': '15',\n",
        " 'This': '16',\n",
        " 'the': '17'}\n",
        "\n",
        " encoded_text = '16 9 15 13 1 2 14 10 4 5 10 6 8 2 17 11 7 12 3'\n",
        "```\n",
        "\n",
        "### Pseudo-code (optional to follow)\n",
        "* convert the text into a list called `tokens`\n",
        "* get a list of all the `unique_tokens`\n",
        "* create an empty dictionary called `mapping`\n",
        "* loop through the unique tokens and add the current token as the `key` in mapping and assign the value of the current iteration as the `value`.\n",
        "* loop through the *range of the length* of tokens and reassign the token at each index to the value that it's mapped to.\n",
        "* use the `join` method to convert the list of encoded tokens back into a string "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 62,
      "metadata": {
        "id": "Q-04NkjAzy14",
        "outputId": "b27382fc-3cc4-4085-83f5-e553d1773a1b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'27 8 19 59 62 24 12 59 49 10 57 4 50 56 15 16 36 68 37 58 64 26 52 72 46 2 61 32 40 1 28 64 37 29 59 48 35 38 65 54 59 63 18 53 25 70 59 66 72 20 7 11 13 5 21 6 30 22 60 33 67 9 69 14 41 10 47 72 55 31 42 43 39 51 7 22 21 34 17 30 44 24 71 23 7 37 45 3'"
            ]
          },
          "metadata": {},
          "execution_count": 62
        }
      ],
      "source": [
        "from random import randint, choice\n",
        "def get_sample_text():\n",
        "    urls = [\n",
        "        \"https://raw.githubusercontent.com/Gabe-flomo/text-generation/master/data/Mindscape%20articles/tokens_13.txt\",\n",
        "        \"https://raw.githubusercontent.com/Gabe-flomo/text-generation/master/data/Mindscape%20articles/tokens_16.txt\",\n",
        "        \"https://raw.githubusercontent.com/Gabe-flomo/text-generation/master/data/Mindscape%20articles/tokens_20.txt\"\n",
        "    ]\n",
        "    lower = randint(0, 100)\n",
        "    upper = randint(99, 2000)\n",
        "    url = choice(urls)\n",
        "    data = requests.get(url).text\n",
        "    data = data.replace(\"\\n\", \" \")\n",
        "    return data[lower:upper]\n",
        "\n",
        "#TODO\n",
        "words = get_sample_text().replace(\"  \",\" \")\n",
        "words = words.split(\" \")\n",
        "words_u = list(set(words))\n",
        "dic = {}\n",
        "for i in words_u:\n",
        "  dic[i] = len(dic) + 1\n",
        "dic\n",
        "sentence = []\n",
        "for i in words:\n",
        "  sentence.append(str(dic[i]))\n",
        "sentence = \" \".join(sentence)\n",
        "sentence\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ToABokgdzy14"
      },
      "source": [
        "# TASK 6\n",
        "Use the `get_word` function from task 3 to generate another 20 words. Count how many words end with `ing`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 65,
      "metadata": {
        "id": "uG5mko5yzy14",
        "outputId": "be48dba2-9f63-4e1c-9989-02290b1c9aea",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1"
            ]
          },
          "metadata": {},
          "execution_count": 65
        }
      ],
      "source": [
        "#TODO\n",
        "count = 0\n",
        "for i in get_word():\n",
        "  if i.endswith(\"ing\"):\n",
        "    count += 1\n",
        "count\n",
        "  "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lthHk3Fszy14"
      },
      "source": [
        "# TASK 7\n",
        "Find all of the numeric strings in the list and find the sum and average of all the numbers.\n",
        "\n",
        "## Example output\n",
        "```python\n",
        "var = [\"1\", \"hello\", \"St\", \"5\", \"22\", \"not a number\", \"15\"]\n",
        "numbers = [1, 5, 22, 15]\n",
        "sum = 43\n",
        "avg = 10.75\n",
        "```\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 68,
      "metadata": {
        "id": "Z5UAat9xzy15",
        "outputId": "75ee1473-9637-4b76-ffe7-11d1738fd4b7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "57.166666666666664"
            ]
          },
          "metadata": {},
          "execution_count": 68
        }
      ],
      "source": [
        "def get_list():\n",
        "    words = get_word()\n",
        "    return [choice([str(randint(0,100)), choice(words)]) for _ in range(20)]\n",
        "\n",
        "var = get_list()\n",
        "\n",
        "#TODO \n",
        "numbers = []\n",
        "for i in var:\n",
        "  if i.isnumeric():\n",
        "    numbers.append(float(i))\n",
        "sum = sum(numbers)\n",
        "avg = sum/len(numbers)\n",
        "avg"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "_k3-zZ1peH3X"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "interpreter": {
      "hash": "f1a916808f2d29f1a5fbd48aa1cb9129993ca703ecce713879d0cd946e898e32"
    },
    "kernelspec": {
      "display_name": "Python 3.9.7 64-bit ('legacy': conda)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.7"
    },
    "orig_nbformat": 4,
    "colab": {
      "name": "string_tasks.ipynb",
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}